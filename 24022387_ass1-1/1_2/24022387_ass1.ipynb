{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206e4bac-d87e-4adf-a923-549348c31828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1077, 64)\n",
      "Val: (360, 64)\n",
      "Test: (360, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load và chia dữ liệu 60/20/20\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y #0.2 test\n",
    ") \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp # 0.25* 0.8 = 0.2 validation\n",
    ")\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a2b898-b2b3-4b85-b43a-c842da64a7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression | Optimize:\n",
      "C = 0.01   | Validation accuracy = 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1    | Validation accuracy = 0.9722\n",
      "C = 1.0    | Validation accuracy = 0.9639\n",
      "C = 10.0   | Validation accuracy = 0.9556\n",
      "C = 100.0  | Validation accuracy = 0.9528\n",
      "\n",
      "Best C on validation set: 0.01, accuracy = 0.9722\n",
      "\n",
      "Logistic Regression | Train \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy (Logistic Regression) = 0.9639\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        36\n",
      "           1       0.91      0.86      0.89        36\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.97      1.00      0.99        37\n",
      "           4       0.92      1.00      0.96        36\n",
      "           5       1.00      1.00      1.00        37\n",
      "           6       1.00      0.97      0.99        36\n",
      "           7       1.00      0.97      0.99        36\n",
      "           8       0.86      0.91      0.89        35\n",
      "           9       0.97      0.94      0.96        36\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "Updated to file: digits_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# 2. Huấn luyện mô hình trên tập train: \n",
    "# (với logistic regression, cần tìm tham số C tối ưu bằng validation rồi mới train full)\n",
    "\n",
    "# 3. Tối ưu C trên validation\n",
    "\n",
    "C_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "best_C = None\n",
    "best_val_acc = 0.0\n",
    "\n",
    "\n",
    "print(\"\\nLogistic Regression | Optimize:\")\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty='l2',\n",
    "        solver='lbfgs',\n",
    "        max_iter=2000,\n",
    "        multi_class='multinomial'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "    print(f\"C = {C:<6} | Validation accuracy = {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_C = C\n",
    "\n",
    "print(f\"\\nBest C on validation set: {best_C}, accuracy = {best_val_acc:.4f}\")\n",
    "\n",
    "# Train lại trên train+val (mô hình cuối cùng)\n",
    "X_train_full = np.vstack([X_train, X_val])\n",
    "y_train_full = np.hstack([y_train, y_val])\n",
    "\n",
    "print(\"\\nLogistic Regression | Train \")\n",
    "\n",
    "best_model = LogisticRegression(\n",
    "    C=best_C,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    max_iter=2000,\n",
    "    multi_class='multinomial'\n",
    ")\n",
    "best_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 4. Test accuracy\n",
    "test_pred = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(f\"\\nTest accuracy (Logistic Regression) = {test_acc:.4f}\\n\")\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_test, test_pred, average='macro'\n",
    ")\n",
    "\n",
    "# 5. Update CSV\n",
    "results_row = {\n",
    "    \"Model\": \"Logistic Regression\",\n",
    "    \"Train size\": X_train.shape[0],\n",
    "    \"Validation size\": X_val.shape[0],\n",
    "    \"Test size\": X_test.shape[0],\n",
    "    \"Hyperparameters\": f\"C={best_C}, penalty=L2, solver=lbfgs, multinomial\",\n",
    "    \"Best validation accuracy\": best_val_acc,\n",
    "    \"Test accuracy\": test_acc,\n",
    "    \"Precision (macro)\": precision_macro,\n",
    "    \"Recall (macro)\": recall_macro,\n",
    "    \"F1-score (macro)\": f1_macro,\n",
    "    \"Notes\": \"random_state=42, no scaling\"\n",
    "}\n",
    "\n",
    "csv_path = \"digits_models_results.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"Model\" in df.columns:\n",
    "        df = df[df[\"Model\"] != \"Logistic Regression\"]\n",
    "    df = pd.concat([df, pd.DataFrame([results_row])], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame([results_row])\n",
    "\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Updated to file: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8bb57f-4fdf-440f-a7e9-cf99fa9cd8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree | Optimize:\n",
      "max_depth=5, criterion=gini, min_samples_split=2 | Val Acc = 0.6667\n",
      "max_depth=5, criterion=gini, min_samples_split=5 | Val Acc = 0.6667\n",
      "max_depth=5, criterion=gini, min_samples_split=10 | Val Acc = 0.6611\n",
      "max_depth=5, criterion=entropy, min_samples_split=2 | Val Acc = 0.7222\n",
      "max_depth=5, criterion=entropy, min_samples_split=5 | Val Acc = 0.7250\n",
      "max_depth=5, criterion=entropy, min_samples_split=10 | Val Acc = 0.7194\n",
      "max_depth=10, criterion=gini, min_samples_split=2 | Val Acc = 0.8389\n",
      "max_depth=10, criterion=gini, min_samples_split=5 | Val Acc = 0.8556\n",
      "max_depth=10, criterion=gini, min_samples_split=10 | Val Acc = 0.8361\n",
      "max_depth=10, criterion=entropy, min_samples_split=2 | Val Acc = 0.8167\n",
      "max_depth=10, criterion=entropy, min_samples_split=5 | Val Acc = 0.8222\n",
      "max_depth=10, criterion=entropy, min_samples_split=10 | Val Acc = 0.8194\n",
      "max_depth=20, criterion=gini, min_samples_split=2 | Val Acc = 0.8333\n",
      "max_depth=20, criterion=gini, min_samples_split=5 | Val Acc = 0.8500\n",
      "max_depth=20, criterion=gini, min_samples_split=10 | Val Acc = 0.8417\n",
      "max_depth=20, criterion=entropy, min_samples_split=2 | Val Acc = 0.8167\n",
      "max_depth=20, criterion=entropy, min_samples_split=5 | Val Acc = 0.8222\n",
      "max_depth=20, criterion=entropy, min_samples_split=10 | Val Acc = 0.8194\n",
      "max_depth=None, criterion=gini, min_samples_split=2 | Val Acc = 0.8333\n",
      "max_depth=None, criterion=gini, min_samples_split=5 | Val Acc = 0.8500\n",
      "max_depth=None, criterion=gini, min_samples_split=10 | Val Acc = 0.8417\n",
      "max_depth=None, criterion=entropy, min_samples_split=2 | Val Acc = 0.8167\n",
      "max_depth=None, criterion=entropy, min_samples_split=5 | Val Acc = 0.8222\n",
      "max_depth=None, criterion=entropy, min_samples_split=10 | Val Acc = 0.8194\n",
      "\n",
      "Best params on validation: (10, 'gini', 5)\n",
      "Best validation accuracy: 0.8555555555555555\n",
      "\n",
      "Decision Tree | Train\n",
      "Test accuracy (Decision Tree) = 0.8278\n",
      "Precision (macro): 0.8273487444739818\n",
      "Recall (macro): 0.826949806949807\n",
      "F1-score (macro): 0.8260098810268955\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        36\n",
      "           1       0.74      0.72      0.73        36\n",
      "           2       0.82      0.80      0.81        35\n",
      "           3       0.78      0.84      0.81        37\n",
      "           4       0.88      0.83      0.86        36\n",
      "           5       0.90      0.95      0.92        37\n",
      "           6       0.79      0.86      0.83        36\n",
      "           7       0.81      0.83      0.82        36\n",
      "           8       0.77      0.69      0.73        35\n",
      "           9       0.88      0.78      0.82        36\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.83      0.83      0.83       360\n",
      "weighted avg       0.83      0.83      0.83       360\n",
      "\n",
      "\n",
      "Updated to file: digits_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# DECISION TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# 2. Huấn luyện mô hình trên tập train:\n",
    "# Với Decision Tree, ta cũng cần tối ưu siêu tham số (max_depth, criterion, min_samples_split) bằng tập validation rồi mới train full train+val.\n",
    "\n",
    "# 3. Tối ưu siêu tham số trên validation\n",
    "max_depth_list = [5, 10, 20, None]\n",
    "criteria = [\"gini\", \"entropy\"]\n",
    "min_samples_list = [2, 5, 10]\n",
    "\n",
    "best_params = None\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"\\nDecision Tree | Optimize:\")\n",
    "for depth in max_depth_list:\n",
    "    for crit in criteria:\n",
    "        for min_s in min_samples_list:\n",
    "\n",
    "            model = DecisionTreeClassifier(\n",
    "                max_depth=depth,\n",
    "                criterion=crit,\n",
    "                min_samples_split=min_s,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "            print(f\"max_depth={depth}, criterion={crit}, min_samples_split={min_s} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_params = (depth, crit, min_s)\n",
    "\n",
    "print(\"\\nBest params on validation:\", best_params)\n",
    "print(\"Best validation accuracy:\", best_val_acc)\n",
    "\n",
    "# 4. Train lại mô hình tốt nhất trên train+val\n",
    "best_depth, best_crit, best_min_s = best_params\n",
    "\n",
    "X_train_full = np.vstack([X_train, X_val])\n",
    "y_train_full = np.hstack([y_train, y_val])\n",
    "\n",
    "best_tree = DecisionTreeClassifier(\n",
    "    max_depth=best_depth,\n",
    "    criterion=best_crit,\n",
    "    min_samples_split=best_min_s,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nDecision Tree | Train\")\n",
    "best_tree.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 4. Test accuracy\n",
    "test_pred = best_tree.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_test, test_pred, average='macro'\n",
    ")\n",
    "\n",
    "print(f\"Test accuracy (Decision Tree) = {test_acc:.4f}\")\n",
    "print(\"Precision (macro):\", precision_macro)\n",
    "print(\"Recall (macro):\", recall_macro)\n",
    "print(\"F1-score (macro):\", f1_macro)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "# 5. Update CSV\n",
    "results_row = {\n",
    "    \"Model\": \"Decision Tree\",\n",
    "    \"Train size\": X_train.shape[0],\n",
    "    \"Validation size\": X_val.shape[0],\n",
    "    \"Test size\": X_test.shape[0],\n",
    "    \"Hyperparameters\": (\n",
    "        f\"max_depth={best_depth}, criterion={best_crit}, \"\n",
    "        f\"min_samples_split={best_min_s}\"\n",
    "    ),\n",
    "    \"Best validation accuracy\": best_val_acc,\n",
    "    \"Test accuracy\": test_acc,\n",
    "    \"Precision (macro)\": precision_macro,\n",
    "    \"Recall (macro)\": recall_macro,\n",
    "    \"F1-score (macro)\": f1_macro,\n",
    "    \"Notes\": \"random_state=42\"\n",
    "}\n",
    "\n",
    "csv_path = \"digits_models_results.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"Model\" in df.columns:\n",
    "        df = df[df[\"Model\"] != \"Decision Tree\"]\n",
    "    df = pd.concat([df, pd.DataFrame([results_row])], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame([results_row])\n",
    "\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nUpdated to file: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e69b1c7-699b-4921-a1b9-3adce369acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN | Optimize: \n",
      "k=1, weights=uniform, metric=euclidean | Val Acc = 0.9889\n",
      "k=1, weights=uniform, metric=manhattan | Val Acc = 0.9833\n",
      "k=1, weights=distance, metric=euclidean | Val Acc = 0.9889\n",
      "k=1, weights=distance, metric=manhattan | Val Acc = 0.9833\n",
      "k=3, weights=uniform, metric=euclidean | Val Acc = 0.9806\n",
      "k=3, weights=uniform, metric=manhattan | Val Acc = 0.9806\n",
      "k=3, weights=distance, metric=euclidean | Val Acc = 0.9806\n",
      "k=3, weights=distance, metric=manhattan | Val Acc = 0.9806\n",
      "k=5, weights=uniform, metric=euclidean | Val Acc = 0.9806\n",
      "k=5, weights=uniform, metric=manhattan | Val Acc = 0.9806\n",
      "k=5, weights=distance, metric=euclidean | Val Acc = 0.9806\n",
      "k=5, weights=distance, metric=manhattan | Val Acc = 0.9806\n",
      "k=7, weights=uniform, metric=euclidean | Val Acc = 0.9806\n",
      "k=7, weights=uniform, metric=manhattan | Val Acc = 0.9778\n",
      "k=7, weights=distance, metric=euclidean | Val Acc = 0.9806\n",
      "k=7, weights=distance, metric=manhattan | Val Acc = 0.9806\n",
      "k=9, weights=uniform, metric=euclidean | Val Acc = 0.9750\n",
      "k=9, weights=uniform, metric=manhattan | Val Acc = 0.9722\n",
      "k=9, weights=distance, metric=euclidean | Val Acc = 0.9750\n",
      "k=9, weights=distance, metric=manhattan | Val Acc = 0.9722\n",
      "k=11, weights=uniform, metric=euclidean | Val Acc = 0.9722\n",
      "k=11, weights=uniform, metric=manhattan | Val Acc = 0.9750\n",
      "k=11, weights=distance, metric=euclidean | Val Acc = 0.9750\n",
      "k=11, weights=distance, metric=manhattan | Val Acc = 0.9750\n",
      "\n",
      "Best params on validation: (1, 'uniform', 'euclidean')\n",
      "Best validation accuracy: 0.9888888888888889\n",
      "KNN | Train\n",
      "\n",
      "Test accuracy (KNN) = 0.9861\n",
      "\n",
      "Precision (macro): 0.9865746865746866\n",
      "Recall (macro): 0.9858730158730159\n",
      "F1-score (macro): 0.985890641187982\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.92      1.00      0.96        36\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       0.97      1.00      0.99        36\n",
      "           5       1.00      1.00      1.00        37\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      1.00      1.00        36\n",
      "           8       0.97      0.91      0.94        35\n",
      "           9       1.00      0.94      0.97        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Updated to file: digits_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# K-NEAREST NEIGHBORS (KNN)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# 2. Huấn luyện mô hình trên tập train:\n",
    "# Với KNN, ta cần tối ưu k (n_neighbors), weights, metric bằng tập validation.\n",
    "\n",
    "# 3. Tối ưu siêu tham số trên validation\n",
    "k_values = [1, 3, 5, 7, 9, 11]\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "metric_options = [\"euclidean\", \"manhattan\"]\n",
    "\n",
    "best_params = None\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"\\nKNN | Optimize: \")\n",
    "for k in k_values:\n",
    "    for w in weight_options:\n",
    "        for m in metric_options:\n",
    "\n",
    "            model = KNeighborsClassifier(\n",
    "                n_neighbors=k,\n",
    "                weights=w,\n",
    "                metric=m\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "            print(f\"k={k}, weights={w}, metric={m} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_params = (k, w, m)\n",
    "\n",
    "print(\"\\nBest params on validation:\", best_params)\n",
    "print(\"Best validation accuracy:\", best_val_acc)\n",
    "\n",
    "# 4. Train lại mô hình tốt nhất trên train+val\n",
    "best_k, best_weight, best_metric = best_params\n",
    "\n",
    "X_train_full = np.vstack([X_train, X_val])\n",
    "y_train_full = np.hstack([y_train, y_val])\n",
    "\n",
    "best_knn = KNeighborsClassifier(\n",
    "    n_neighbors=best_k,\n",
    "    weights=best_weight,\n",
    "    metric=best_metric\n",
    ")\n",
    "\n",
    "print(\"KNN | Train\")\n",
    "best_knn.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 4. Test accuracy\n",
    "test_pred = best_knn.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_test, test_pred, average='macro'\n",
    ")\n",
    "\n",
    "print(f\"\\nTest accuracy (KNN) = {test_acc:.4f}\\n\")\n",
    "print(\"Precision (macro):\", precision_macro)\n",
    "print(\"Recall (macro):\", recall_macro)\n",
    "print(\"F1-score (macro):\", f1_macro)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "# 5. Update CSV\n",
    "results_row = {\n",
    "    \"Model\": \"KNN\",\n",
    "    \"Train size\": X_train.shape[0],\n",
    "    \"Validation size\": X_val.shape[0],\n",
    "    \"Test size\": X_test.shape[0],\n",
    "    \"Hyperparameters\": (\n",
    "        f\"k={best_k}, weights={best_weight}, metric={best_metric}\"\n",
    "    ),\n",
    "    \"Best validation accuracy\": best_val_acc,\n",
    "    \"Test accuracy\": test_acc,\n",
    "    \"Precision (macro)\": precision_macro,\n",
    "    \"Recall (macro)\": recall_macro,\n",
    "    \"F1-score (macro)\": f1_macro,\n",
    "    \"Notes\": \"KNN không cần random_state\"\n",
    "}\n",
    "\n",
    "csv_path = \"digits_models_results.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"Model\" in df.columns:\n",
    "        df = df[df[\"Model\"] != \"KNN\"]\n",
    "    df = pd.concat([df, pd.DataFrame([results_row])], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame([results_row])\n",
    "\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nUpdated to file: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283e7ea6-0580-4eba-bd62-3ed717ac2ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN (MLP) | Optimize: \n",
      "hidden=(50,), activation=relu, alpha=0.0001 | Val Acc = 0.9528\n",
      "hidden=(50,), activation=relu, alpha=0.001 | Val Acc = 0.9583\n",
      "hidden=(50,), activation=tanh, alpha=0.0001 | Val Acc = 0.9667\n",
      "hidden=(50,), activation=tanh, alpha=0.001 | Val Acc = 0.9667\n",
      "hidden=(100,), activation=relu, alpha=0.0001 | Val Acc = 0.9750\n",
      "hidden=(100,), activation=relu, alpha=0.001 | Val Acc = 0.9750\n",
      "hidden=(100,), activation=tanh, alpha=0.0001 | Val Acc = 0.9694\n",
      "hidden=(100,), activation=tanh, alpha=0.001 | Val Acc = 0.9722\n",
      "hidden=(50, 50), activation=relu, alpha=0.0001 | Val Acc = 0.9667\n",
      "hidden=(50, 50), activation=relu, alpha=0.001 | Val Acc = 0.9694\n",
      "hidden=(50, 50), activation=tanh, alpha=0.0001 | Val Acc = 0.9500\n",
      "hidden=(50, 50), activation=tanh, alpha=0.001 | Val Acc = 0.9500\n",
      "\n",
      "Best params on validation: ((100,), 'relu', 0.0001)\n",
      "Best validation accuracy: 0.975\n",
      "ANN (MLP) | Train\n",
      "\n",
      "Test accuracy (ANN - MLP) = 0.9889\n",
      "\n",
      "Precision (macro): 0.9889287612971824\n",
      "Recall (macro): 0.9886507936507936\n",
      "F1-score (macro): 0.9885980429476702\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.95      1.00      0.97        36\n",
      "           2       0.97      1.00      0.99        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        37\n",
      "           6       1.00      0.97      0.99        36\n",
      "           7       1.00      1.00      1.00        36\n",
      "           8       0.97      0.91      0.94        35\n",
      "           9       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Updated to file: digits_models_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ARTIFICIAL NEURAL NETWORK (MLP)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# 2. Huấn luyện mô hình trên tập train:\n",
    "# Với ANN (MLP), ta cần tối ưu siêu tham số (hidden_layer_sizes, activation, alpha) bằng tập validation rồi mới train full train+val.\n",
    "\n",
    "# 3. Tối ưu siêu tham số trên validation\n",
    "hidden_layer_list = [\n",
    "    (50,),\n",
    "    (100,),\n",
    "    (50, 50)\n",
    "]\n",
    "activation_list = [\"relu\", \"tanh\"]\n",
    "alpha_list = [0.0001, 0.001]\n",
    "\n",
    "best_params = None\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"ANN (MLP) | Optimize: \")\n",
    "for hidden in hidden_layer_list:\n",
    "    for act in activation_list:\n",
    "        for alpha in alpha_list:\n",
    "\n",
    "            model = MLPClassifier(\n",
    "                hidden_layer_sizes=hidden,\n",
    "                activation=act,\n",
    "                alpha=alpha,\n",
    "                max_iter=300,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "            print(f\"hidden={hidden}, activation={act}, alpha={alpha} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_params = (hidden, act, alpha)\n",
    "\n",
    "print(\"\\nBest params on validation:\", best_params)\n",
    "print(\"Best validation accuracy:\", best_val_acc)\n",
    "\n",
    "# 4. Train lại mô hình tốt nhất trên train+val\n",
    "best_hidden, best_act, best_alpha = best_params\n",
    "\n",
    "X_train_full = np.vstack([X_train, X_val])\n",
    "y_train_full = np.hstack([y_train, y_val])\n",
    "\n",
    "best_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=best_hidden,\n",
    "    activation=best_act,\n",
    "    alpha=best_alpha,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"ANN (MLP) | Train\")\n",
    "best_mlp.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 4. Test accuracy\n",
    "test_pred = best_mlp.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_test, test_pred, average='macro'\n",
    ")\n",
    "\n",
    "print(f\"\\nTest accuracy (ANN - MLP) = {test_acc:.4f}\\n\")\n",
    "print(\"Precision (macro):\", precision_macro)\n",
    "print(\"Recall (macro):\", recall_macro)\n",
    "print(\"F1-score (macro):\", f1_macro)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "# 5. Update CSV\n",
    "results_row = {\n",
    "    \"Model\": \"Neural Network (MLP)\",\n",
    "    \"Train size\": X_train.shape[0],\n",
    "    \"Validation size\": X_val.shape[0],\n",
    "    \"Test size\": X_test.shape[0],\n",
    "    \"Hyperparameters\": (\n",
    "        f\"hidden={best_hidden}, activation={best_act}, alpha={best_alpha}, \"\n",
    "        f\"max_iter=300\"\n",
    "    ),\n",
    "    \"Best validation accuracy\": best_val_acc,\n",
    "    \"Test accuracy\": test_acc,\n",
    "    \"Precision (macro)\": precision_macro,\n",
    "    \"Recall (macro)\": recall_macro,\n",
    "    \"F1-score (macro)\": f1_macro,\n",
    "    \"Notes\": \"random_state=42, no scaling\"\n",
    "}\n",
    "\n",
    "csv_path = \"digits_models_results.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"Model\" in df.columns:\n",
    "        df = df[df[\"Model\"] != \"Neural Network (MLP)\"]\n",
    "    df = pd.concat([df, pd.DataFrame([results_row])], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame([results_row])\n",
    "\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nUpdated to file: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "314ff99f-ad84-4aec-95cf-6a2efe78de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Train size  Validation size  Test size  \\\n",
      "0   Logistic Regression        1077              360        360   \n",
      "1         Decision Tree        1077              360        360   \n",
      "2                   KNN        1077              360        360   \n",
      "3  Neural Network (MLP)        1077              360        360   \n",
      "\n",
      "                                     Hyperparameters  \\\n",
      "0      C=0.01, penalty=L2, solver=lbfgs, multinomial   \n",
      "1  max_depth=10, criterion=gini, min_samples_split=5   \n",
      "2             k=1, weights=uniform, metric=euclidean   \n",
      "3  hidden=(100,), activation=relu, alpha=0.0001, ...   \n",
      "\n",
      "   Best validation accuracy  Test accuracy  Precision (macro)  Recall (macro)  \\\n",
      "0                  0.972222       0.963889           0.964482        0.963651   \n",
      "1                  0.855556       0.827778           0.827349        0.826950   \n",
      "2                  0.988889       0.986111           0.986575        0.985873   \n",
      "3                  0.975000       0.988889           0.988929        0.988651   \n",
      "\n",
      "   F1-score (macro)                        Notes  \n",
      "0          0.963676  random_state=42, no scaling  \n",
      "1          0.826010              random_state=42  \n",
      "2          0.985891   KNN không cần random_state  \n",
      "3          0.988598  random_state=42, no scaling  \n",
      "NHẬN XÉT (CHATGPT) \n",
      "\n",
      "Dựa trên bảng kết quả 4 mô hình:\n",
      "\n",
      "- **Mô hình có độ chính xác cao nhất** là: **Neural Network (MLP)**, với Test Accuracy = **0.9889**.\n",
      "- **Mô hình có độ chính xác thấp nhất** là: **Decision Tree**, với Test Accuracy = **0.8278**.\n",
      "\n",
      "- Trung bình F1-score của các mô hình là: **0.9410**.\n",
      "\n",
      "**Nhận xét tổng quát:**\n",
      "\n",
      "• Neural Network (MLP) cho kết quả tốt nhất, cho thấy mô hình này phù hợp nhất với đặc trưng của bộ dữ liệu Digits.\n",
      "\n",
      "• Các mô hình còn lại cho hiệu quả khác nhau tùy vào bản chất:\n",
      "  - Logistic Regression hoạt động ổn định, ít overfit.\n",
      "  - Decision Tree dễ overfit, nên accuracy thấp hơn.\n",
      "  - KNN có performance khá cao nhưng phụ thuộc mạnh vào k và metric.\n",
      "  - Neural Network (MLP) có khả năng học phi tuyến tốt, nhưng cần tuning nhiều siêu tham số.\n",
      "\n",
      "• Tùy mục tiêu ứng dụng thực tế:\n",
      "  - Nếu ưu tiên **đơn giản và ổn định** → Logistic Regression hoặc KNN.\n",
      "  - Nếu ưu tiên **diễn giải mô hình** → Decision Tree.\n",
      "  - Nếu cần **khả năng học phi tuyến mạnh nhất** → MLP (ANN).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = \"digits_models_results.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print (df)\n",
    "\n",
    "print(\"NHẬN XÉT (CHATGPT) \\n\")\n",
    "\n",
    "# 1. Tìm model tốt nhất theo Test Accuracy\n",
    "best_model_row = df.loc[df[\"Test accuracy\"].idxmax()]\n",
    "best_model_name = best_model_row[\"Model\"]\n",
    "best_acc = best_model_row[\"Test accuracy\"]\n",
    "\n",
    "# 2. Tìm model tệ nhất\n",
    "worst_model_row = df.loc[df[\"Test accuracy\"].idxmin()]\n",
    "worst_model_name = worst_model_row[\"Model\"]\n",
    "worst_acc = worst_model_row[\"Test accuracy\"]\n",
    "\n",
    "# 3. Tính trung bình F1\n",
    "df[\"F1-score (macro)\"] = pd.to_numeric(df[\"F1-score (macro)\"], errors=\"coerce\")\n",
    "avg_f1 = df[\"F1-score (macro)\"].mean()\n",
    "\n",
    "# 4. Sinh nhận xét tự động\n",
    "print(\"Dựa trên bảng kết quả 4 mô hình:\\n\")\n",
    "\n",
    "print(f\"- **Mô hình có độ chính xác cao nhất** là: **{best_model_name}**, với Test Accuracy = **{best_acc:.4f}**.\")\n",
    "print(f\"- **Mô hình có độ chính xác thấp nhất** là: **{worst_model_name}**, với Test Accuracy = **{worst_acc:.4f}**.\\n\")\n",
    "\n",
    "print(f\"- Trung bình F1-score của các mô hình là: **{avg_f1:.4f}**.\\n\")\n",
    "\n",
    "print(\"**Nhận xét tổng quát:**\")\n",
    "\n",
    "print(f\"\"\"\n",
    "• {best_model_name} cho kết quả tốt nhất, cho thấy mô hình này phù hợp nhất với đặc trưng của bộ dữ liệu Digits.\n",
    "\n",
    "• Các mô hình còn lại cho hiệu quả khác nhau tùy vào bản chất:\n",
    "  - Logistic Regression hoạt động ổn định, ít overfit.\n",
    "  - Decision Tree dễ overfit, nên accuracy thấp hơn.\n",
    "  - KNN có performance khá cao nhưng phụ thuộc mạnh vào k và metric.\n",
    "  - Neural Network (MLP) có khả năng học phi tuyến tốt, nhưng cần tuning nhiều siêu tham số.\n",
    "\n",
    "• Tùy mục tiêu ứng dụng thực tế:\n",
    "  - Nếu ưu tiên **đơn giản và ổn định** → Logistic Regression hoặc KNN.\n",
    "  - Nếu ưu tiên **diễn giải mô hình** → Decision Tree.\n",
    "  - Nếu cần **khả năng học phi tuyến mạnh nhất** → MLP (ANN).\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f774d-d519-477d-86a4-ec8efb6525a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
